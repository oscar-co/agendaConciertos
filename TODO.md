Perfecto ğŸ‘Œ
Te lo genero en formato Markdown checklist, listo para copiar como REFACTOR_PLAN.md en la raÃ­z del proyecto.

ğŸ“¦ AgendaConcerts â€“ Refactor & Improvement Roadmap

Documento de mejoras progresivas para evolucionar el proyecto de forma limpia y escalable.

ğŸŸ¢ FASE 1 â€“ Mejoras de Bajo Riesgo (Alta Rentabilidad)
â¬œ 1. Cache de venues en memoria
Crear venue_cache: dict[str, int]
Evitar SELECT repetidos en cada concierto
Reducir llamadas innecesarias a BD
Mejorar rendimiento en scrapes grandes

â¬œ 2. Argumentos CLI con argparse
AÃ±adir --limit
AÃ±adir --debug
AÃ±adir --no-json
AÃ±adir --city
Permitir ejecutar el scraper sin tocar cÃ³digo

â¬œ 3. Logging estructurado (en vez de print)
Configurar mÃ³dulo logging
Definir niveles: DEBUG / INFO / WARNING / ERROR
Activar debug HTML solo en modo DEBUG
Reducir ruido en ejecuciÃ³n normal

ğŸŸ¡ FASE 2 â€“ Mejora de Modelo y Consistencia
â¬œ 4. Crear ConcertDTO (dataclass)
Reemplazar dict por objeto tipado
Evitar errores de keys mal escritas
Mejorar autocompletado
Facilitar validaciÃ³n futura

â¬œ 5. NormalizaciÃ³n centralizada
Parsers devuelven datos "raw"
FunciÃ³n comÃºn normaliza fechas y horas
El sistema solo maneja date y time
Evitar lÃ³gica duplicada en parsers

â¬œ 6. MÃ©tricas reales (insert vs update)
Diferenciar:
nuevos conciertos
actualizados
ignorados
Mejorar trazabilidad del scraper

ğŸŸ  FASE 3 â€“ Arquitectura y Escalabilidad
â¬œ 7. Salida JSON por ciudad
Generar concerts_{city}.json
O incluir city dentro de cada concierto
Preparar soporte multi-ciudad

â¬œ 8. Separar completamente a paquete agenda_concerts/
Mover todo el cÃ³digo dentro de un paquete
Mejorar imports
Preparar para tests y packaging futuro

â¬œ 9. Tests de parsers (HTML fijo)
Guardar HTML de ejemplo
Crear tests en tests/parsers/
Validar nÃºmero de conciertos
Validar fechas y horas correctas
Detectar roturas cuando cambie el HTML real

â¬œ 10. Fetch robusto con retry y backoff
Implementar 3 reintentos
Backoff exponencial
No romper ejecuciÃ³n si una sala falla
Logging adecuado de errores HTTP

ğŸ”µ FASE 4 â€“ ProfesionalizaciÃ³n
â¬œ 11. AÃ±adir mÃ©tricas bÃ¡sicas
Tiempo total de ejecuciÃ³n
Tiempo por venue
NÃºmero total de conciertos procesados

â¬œ 12. Dockerizar scraper independiente
Servicio separado del backend
Programable por cron
Preparado para despliegue en servidor

â¬œ 13. Preparar migraciones con Alembic
Versionado de esquema
EvoluciÃ³n controlada de la base de datos

ğŸ§  RecomendaciÃ³n de Orden
Orden sugerido de implementaciÃ³n:
1ï¸âƒ£ Cache de venues
2ï¸âƒ£ CLI con argparse
3ï¸âƒ£ Logging
4ï¸âƒ£ DTO
5ï¸âƒ£ Tests
6ï¸âƒ£ ReestructuraciÃ³n de paquete

ğŸ¯ Objetivo Final

Tener un scraper:
Modular
Escalable
Seguro ante duplicados
Preparado para mÃºltiples ciudades
FÃ¡cil de mantener cuando las webs cambien